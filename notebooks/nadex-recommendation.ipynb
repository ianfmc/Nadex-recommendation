{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f07e057-7ee1-4187-adbc-01870d6e2a8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Load** the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135450a-c614-4608-9a4f-a980e289b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numexpr --quiet\n",
    "\n",
    "!pip install pandas --quiet\n",
    "!pip install datetime --quiet\n",
    "!pip install feedparser --quiet\n",
    "!pip install textblob --quiet\n",
    "!pip install yfinance --quiet\n",
    "!pip install requests --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81118871-b728-48e5-831d-f8416ff02d45",
   "metadata": {},
   "source": [
    "**Define a function to get the pricing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0da0a-4253-43ca-9c8e-62a1a0c5876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List, Tuple\n",
    "\n",
    "def fetch_price(ticker: str,\n",
    "               period: str, \n",
    "               interval: str) -> pd.DataFrame:\n",
    "    df = yf.download(ticker, period=period, interval=interval, auto_adjust=True, progress=False)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df.reset_index(inplace=True) \n",
    "    df.columns.name = None\n",
    "    df['ticker'] = ticker\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a462df1-7648-4934-8487-fa19c5de5495",
   "metadata": {},
   "source": [
    "**Define a function to compute the technical indicators**\n",
    "1. Compute the MACD\n",
    "2. Compute the RSI\n",
    "3. Compute the ATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5833a-1a6f-4854-9c5d-cab34bcee3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with EMA12, EMA26, MACD, Signal, and MACD_hist added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD']  = df['EMA12'] - df['EMA26']\n",
    "    df['Signal']   = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_hist'] = df['MACD'] - df['Signal']\n",
    "    return df\n",
    "\n",
    "def compute_rsi(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period RSI column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    return df\n",
    "\n",
    "def compute_atr(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period ATR column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    prev_close = df['Close'].shift(1)\n",
    "    tr1 = df['High'] - df['Low']\n",
    "    tr2 = (df['High'] - prev_close).abs()\n",
    "    tr3 = (df['Low']  - prev_close).abs()\n",
    "    df['ATR'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1).rolling(window=window).mean()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b7427-6257-407d-b996-cce27aaab9fc",
   "metadata": {},
   "source": [
    "**Define a function to load the strike prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018b7b6-74b5-4f15-8f2c-b4d9206518d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_strikes(\n",
    "    path: str,\n",
    "    strike_col: str = \"strike\",\n",
    "    decimals: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1. Reads a CSV from `path`\n",
    "    2. Normalizes column names to lowercase & stripped\n",
    "    3. Ensures there's a numeric `strike_col`, stripping whitespace, converting to float, and rounding\n",
    "    \n",
    "    Returns the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pd.read_csv(path)\n",
    "          # normalize headers: strip whitespace, lowercase\n",
    "          .rename(columns=lambda c: c.strip().lower())\n",
    "          # strip & convert the strike column to numeric, then round\n",
    "          .assign(**{\n",
    "              strike_col: lambda df: (\n",
    "                  pd.to_numeric(\n",
    "                      df[strike_col]\n",
    "                        .astype(str)\n",
    "                        .str.strip(),\n",
    "                      errors=\"raise\"\n",
    "                  )\n",
    "                  .round(decimals)\n",
    "              )\n",
    "          })\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e818b8-8fa1-4cec-8a69-1ec208a838fc",
   "metadata": {},
   "source": [
    "**Define a function to determine the trading signal**\n",
    "1. Determine the Trend\n",
    "2. Check the Momentum\n",
    "3. Determine the Trigger\n",
    "4. Check the Volatility\n",
    "5. Generate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889eb1cd-4e7d-430d-bbdb-2a4d2c8edd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_trend(row):\n",
    "    \"\"\"\n",
    "    Returns (trend_str, ema_diff) where ema_diff = EMA12 − EMA26.\n",
    "    \"\"\"\n",
    "    diff = row.EMA12 - row.EMA26\n",
    "    if (row.EMA12 > row.EMA26) and (row.Close > row.EMA12) and (row.Close > row.EMA26):\n",
    "        trend = 'up'\n",
    "    elif (row.EMA12 < row.EMA26) and (row.Close < row.EMA12) and (row.Close < row.EMA26):\n",
    "        trend = 'down'\n",
    "    else:\n",
    "        trend = 'sideways'\n",
    "    return trend, diff\n",
    "\n",
    "def momentum_check(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, rsi) where ok is True/False and rsi is the raw RSI value.\n",
    "    \"\"\"\n",
    "    rsi = row.RSI\n",
    "    if trend == 'up':\n",
    "        ok = (rsi > 50) and ((row.MACD > row.Signal) or (row.MACD_hist > 0))\n",
    "    elif trend == 'down':\n",
    "        ok = (rsi < 50) and ((row.MACD < row.Signal) or (row.MACD_hist < 0))\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, rsi\n",
    "\n",
    "def signal_trigger(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, macd_diff) where macd_diff = MACD − Signal.\n",
    "    \"\"\"\n",
    "    macd_diff = row.MACD - row.Signal\n",
    "    if trend == 'up':\n",
    "        ok = (macd_diff > 0) and (row.RSI > 50)\n",
    "    elif trend == 'down':\n",
    "        ok = (macd_diff < 0) and (row.RSI < 50)\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, macd_diff\n",
    "\n",
    "def volatility_check(row, strike_diff):\n",
    "    \"\"\"\n",
    "    Returns (ok, strike_diff) so you have the raw distance too.\n",
    "    \"\"\"\n",
    "    ok = strike_diff <= 0.5 * row.ATR\n",
    "    return ok, strike_diff\n",
    "\n",
    "def signal_detail_for_row(row, per_ticker, expiry=\"EOD\"):\n",
    "    df = per_ticker[row.ticker]\n",
    "    last = df.iloc[-1]\n",
    "\n",
    "    trend, trend_val = determine_trend(last)\n",
    "    momentum_ok, momentum_val = momentum_check(last, trend)\n",
    "    sig_ok, signal_val = signal_trigger(last, trend)\n",
    "    strike_diff = abs(row.strike - last.Close)\n",
    "    vol_ok, vol_val = volatility_check(last, strike_diff)\n",
    "\n",
    "    # build recommendation + contract price\n",
    "    if (trend == 'sideways'\n",
    "        or not momentum_ok\n",
    "        or not sig_ok\n",
    "        or not vol_ok\n",
    "    ):\n",
    "        rec   = \"No trade\"\n",
    "        price = pd.NA\n",
    "    else:\n",
    "        direction = \"Buy\" if trend == \"up\" else \"Sell\"\n",
    "        price     = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "        rec       = direction\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Date\":           pd.Timestamp.now().strftime(\"%d-%b-%y\"),\n",
    "        \"Ticker\":         row.ticker,\n",
    "        \"Strike\":         row.strike,\n",
    "        \"EMA12\":          last.EMA12,\n",
    "        \"EMA26\":          last.EMA26,\n",
    "        \"MACD\":           last.MACD,\n",
    "        \"RSI\":            last.RSI,\n",
    "        \"ATR\":            last.ATR,\n",
    "        \"Recommendation\": rec,\n",
    "        \"ContractPrice\":  price,\n",
    "        \"Trend\":          trend_val,\n",
    "        \"Momentum\":       momentum_val,\n",
    "        \"Signal\":         signal_val,\n",
    "        \"Volatility\":     vol_val\n",
    "    })\n",
    "\n",
    "def generate_detailed_signals(per_ticker: dict[str,pd.DataFrame],\n",
    "                              strikes_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies signal_detail_for_row to every strike, returning a DataFrame\n",
    "    with separate columns for both the boolean/string and the raw measure.\n",
    "    \"\"\"\n",
    "    return strikes_df.apply(\n",
    "        lambda r: signal_detail_for_row(r, per_ticker),\n",
    "        axis=1\n",
    "    )    \n",
    "\n",
    "def generate_trade_signal(df: pd.DataFrame, asset_symbol: str, strike_price: float, expiry=\"EOD\") -> str:\n",
    "    \"\"\"\n",
    "    Look only at the *last* row of df and decide on a trade recommendation.\n",
    "    \"\"\"\n",
    "    last = df.iloc[-1]\n",
    "    trend = determine_trend(last)\n",
    "    if trend == 'sideways':\n",
    "        return \"No trade: Trend unclear.\"\n",
    "    if trend == 'down':\n",
    "        # optional debug print\n",
    "        print(f\"Down trend for {asset_symbol} at {strike_price:.4f}\")\n",
    "\n",
    "    if not momentum_check(last, trend):\n",
    "        return \"No trade: Momentum not aligned.\"\n",
    "    if not signal_trigger(last, trend):\n",
    "        return \"No trade: No signal trigger.\"\n",
    "\n",
    "    strike_diff = abs(strike_price - last.Close)\n",
    "    if not volatility_check(last, strike_diff):\n",
    "        return \"No trade: Strike too far based on ATR.\"\n",
    "\n",
    "    # crude price proxy\n",
    "    price_est = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "    direction = \"Buy\" if trend == 'up' else \"Sell\"\n",
    "    return (\n",
    "        f\"{direction} {asset_symbol} @ {strike_price:.4f} (EOD) ≈ ${price_est:.1f}. \"\n",
    "        f\"{trend.title()} trend, momentum/signal OK, volatility OK.\"\n",
    "    )\n",
    "\n",
    "def generate_all_signals(\n",
    "    per_ticker: dict[str, pd.DataFrame], \n",
    "    strikes_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row in strikes_df, look up its ticker-DF in per_ticker and\n",
    "    call generate_trade_signal.  Returns a DataFrame of recommendations.\n",
    "    \"\"\"\n",
    "    out = (\n",
    "        strikes_df\n",
    "        .assign(\n",
    "            Date=pd.Timestamp.now().strftime('%d-%b-%y'),\n",
    "            Signal=lambda d: d.apply(\n",
    "                lambda r: generate_trade_signal(\n",
    "                    per_ticker[r.ticker],\n",
    "                    r.ticker,\n",
    "                    r.strike\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        .rename(columns={'ticker':'Ticker', 'strike':'Strike'})\n",
    "        [['Date','Ticker','Strike','Signal']]\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0786f5-e146-4cf1-9c88-0978f4e6d6e9",
   "metadata": {},
   "source": [
    "**Define a function to upload the recommendations to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e597f1d-9032-4da6-a35d-ce15f3dde6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "from typing import Iterable, List, Dict\n",
    "\n",
    "def create_s3_clients(\n",
    "    profile: str = \"default\", region: str = None  # Changed default\n",
    ") -> Dict[str, boto3.client]:\n",
    "    # Use the region from config if not provided\n",
    "    if region is None:\n",
    "        region = REGION  # Will use value from s3.yaml\n",
    "    \n",
    "    session = boto3.Session(profile_name=profile, region_name=region)\n",
    "    return {\n",
    "        \"public\": session.client(\n",
    "            \"s3\",\n",
    "            config=Config(signature_version=UNSIGNED),\n",
    "            region_name=region,\n",
    "        ),\n",
    "        \"private\": session.client(\"s3\"),\n",
    "        \"resource\": session.resource(\"s3\"),\n",
    "    }\n",
    "\n",
    "def get_bucket(resource: boto3.resource, name: str):\n",
    "    return resource.Bucket(name)\n",
    "\n",
    "def upload_df_to_s3(\n",
    "    df: pd.DataFrame,\n",
    "    bucket: str,\n",
    "    key: str,\n",
    "    region: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to S3 as CSV. Verifies bucket existence first.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    bucket : str\n",
    "        Name of the S3 bucket (no leading/trailing spaces).\n",
    "    key : str\n",
    "        S3 object key, e.g. \"csv/2025-06-28-results.csv\"\n",
    "    region : str, optional\n",
    "        AWS region where the bucket resides.\n",
    "    \"\"\"\n",
    "    bucket = bucket.strip()\n",
    "    s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket)\n",
    "    except ClientError as e:\n",
    "        code = e.response['Error']['Code']\n",
    "        msg = e.response['Error']['Message']\n",
    "        raise RuntimeError(\n",
    "            f\"Could not access bucket '{bucket}' (region={region}): {msg} (code {code})\"\n",
    "        ) from e\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        s3.put_object(Bucket=bucket, Key=key, Body=buffer.getvalue())\n",
    "        print(f\"✅ Uploaded to s3://{bucket}/{key}\")\n",
    "    except ClientError as e:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to upload CSV to s3://{bucket}/{key}: \"\n",
    "            f\"{e.response['Error']['Message']}\"\n",
    "        ) from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1b12-c689-414c-a739-0a7dea03c8b6",
   "metadata": {},
   "source": [
    "**Define a function to run the Pipeline**\n",
    "1. Collect pricing data\n",
    "2. Compute the technical indicators\n",
    "3. Compute the trading signals\n",
    "4. Compare with the day's Strike prices\n",
    "5. Upload the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098fd63-8ecb-45f6-8908-78d9ef151c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "def run_recommendation_pipeline(tickers: List,\n",
    "                               bucket_name: str,\n",
    "                               period: str,\n",
    "                               interval: str,\n",
    "                               mapping_file: str,\n",
    "                               region: str = None) -> pd.DataFrame:  # Add region param\n",
    "    \"\"\"\n",
    "    Fetch price, compute indicators, load strikes,\n",
    "    and return a DataFrame of trade signals.\n",
    "    \"\"\"\n",
    "    clients = create_s3_clients(region=region)  # Pass region\n",
    "    public_s3 = clients[\"public\"]\n",
    "    private_s3 = clients[\"private\"]\n",
    "    s3_resource = clients[\"resource\"]\n",
    "    buckets = {\n",
    "        \"daily\":  get_bucket(s3_resource, bucket_name),\n",
    "    }\n",
    "\n",
    "    ticker_price_data = [\n",
    "        (ticker, fetch_price(ticker, period, interval))\n",
    "        for ticker in tickers\n",
    "    ]\n",
    "\n",
    "    processed = {\n",
    "        ticker: (\n",
    "            df\n",
    "              .pipe(compute_macd)\n",
    "              .pipe(compute_rsi)\n",
    "              .pipe(compute_atr)\n",
    "        )\n",
    "        for ticker, df in ticker_price_data\n",
    "    }\n",
    "    strikes_df = load_strikes(mapping_file)\n",
    "    signals_df = generate_detailed_signals(processed, strikes_df)\n",
    "\n",
    "    today_str = date.today().strftime('%Y%m%d')\n",
    "\n",
    "    s3_key = f\"{RECS_PREFIX}/{today_str}.csv\"\n",
    "    upload_df_to_s3(\n",
    "        signals_df,\n",
    "        bucket_name,\n",
    "        s3_key,\n",
    "        region=region  # Add this line\n",
    "    )\n",
    "    return signals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d39070-1575-404b-b913-5db05955047b",
   "metadata": {},
   "source": [
    "**Define a function to show interesting trades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e8131-e1e0-4856-a7d1-4c271cd7ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def show_interesting_trades(df: pd.DataFrame) -> str:\n",
    "    interesting_trades_df = df[\n",
    "        ~df['Recommendation']\n",
    "            .str.contains(\"No trade\", case=False, na=False)\n",
    "    ]\n",
    "    if not interesting_trades_df.empty:\n",
    "        print(\n",
    "            tabulate(\n",
    "                interesting_trades_df[[\"Date\",\"Ticker\",\"Recommendation\",\"Strike\",\"ContractPrice\"]],\n",
    "                headers='keys',\n",
    "                tablefmt='fancy_grid',\n",
    "                showindex=False,        \n",
    "                maxcolwidths=200  \n",
    "            )\n",
    "        )\n",
    "        return 'Success'\n",
    "    else:\n",
    "        print(\"No trades recommended today\")\n",
    "        return 'Failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a12b8-4075-4f3e-907c-57d197aa934c",
   "metadata": {},
   "source": [
    "**Load from configuration files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cf079-7be9-4f19-b791-d4392d313555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config (run from inside notebooks/)\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../lib\")  # so we can \"from lib import ...\" package-style\n",
    "\n",
    "from strategy_rsi import generate_rsi_signals      # shared RSI/MACD/centerline/reversal logic\n",
    "# (Optional) other helpers you'll likely use:\n",
    "from utils_s3 import save_dataframe_to_s3, save_text_to_s3, append_runlog_s3\n",
    "\n",
    "# s3 + strategy configs\n",
    "with open('../configs/s3.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# S3 targets / prefixes\n",
    "BUCKET = cfg['bucket']\n",
    "REGION = cfg.get('region')\n",
    "RECS_PREFIX = cfg['prefixes'].get('recommendations', 'recommendations')\n",
    "REPORTS_PREFIX = cfg['prefixes'].get('reports', 'reports')\n",
    "RUNLOG_KEY = f\"{cfg['prefixes'].get('logs','logs')}/run_log.csv\"\n",
    "\n",
    "print(f\"Region = {REGION}\")\n",
    "\n",
    "# Optional mapping file (primarily used by Nadex-results; harmless if unused here)\n",
    "MAPPING_FILE = Path(cfg.get('mapping_file')).resolve() if cfg.get('mapping_file') else None\n",
    "\n",
    "# Optional: guard to prevent accidental hard-coding at runtime\n",
    "ALLOWED_BUCKETS = {BUCKET}\n",
    "\n",
    "def assert_allowed_bucket(b):\n",
    "    if b not in ALLOWED_BUCKETS:\n",
    "        raise ValueError(\n",
    "            f\"Bucket '{b}' not allowed; use cfg['bucket'] from s3.yaml.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd149492-15be-4bcf-9023-3ae110365abf",
   "metadata": {},
   "source": [
    "**Record in the Run Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972a634-417f-46de-88b5-7488b145711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "with open('../configs/s3.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    \n",
    "# Run log helper (append a row to S3 CSV)\n",
    "import io, csv, datetime as dt\n",
    "from botocore.exceptions import ClientError  # comes with boto3\n",
    "\n",
    "RUNLOG_FIELDS = [\n",
    "    'date','start_time','end_time','status',\n",
    "    'files_processed','files_skipped','files_error',\n",
    "    'run_id','notes'\n",
    "]\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "session = boto3.Session(region_name=cfg.get('region'))\n",
    "private_s3 = session.client('s3')\n",
    "public_s3 = session.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "def append_runlog_s3(\n",
    "    bucket: str,\n",
    "    key: str,\n",
    "    *,\n",
    "    start_time=None,\n",
    "    status='success',\n",
    "    files_processed=0,\n",
    "    files_skipped=0,\n",
    "    files_error=0,\n",
    "    run_id='',\n",
    "    notes=''\n",
    "):\n",
    "    now = dt.datetime.now()\n",
    "    start = start_time or now\n",
    "\n",
    "    row = {\n",
    "        'date': now.date().isoformat(),\n",
    "        'start_time': start if isinstance(start, str) else start.isoformat(timespec='seconds'),\n",
    "        'end_time': now.isoformat(timespec='seconds'),\n",
    "        'status': status,\n",
    "        'files_processed': int(files_processed),\n",
    "        'files_skipped': int(files_skipped),\n",
    "        'files_error': int(files_error),\n",
    "        'run_id': run_id,\n",
    "        'notes': notes,\n",
    "    }\n",
    "\n",
    "    # Fetch existing (if present)\n",
    "    buf = io.StringIO()\n",
    "    need_header = False\n",
    "    try:\n",
    "        obj = private_s3.get_object(Bucket=bucket, Key=key)\n",
    "        buf.write(obj['Body'].read().decode('utf-8'))\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] in ('NoSuchKey', '404'):\n",
    "            need_header = True\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    if buf.tell() == 0:\n",
    "        need_header = True\n",
    "\n",
    "    writer = csv.DictWriter(buf, fieldnames=RUNLOG_FIELDS)\n",
    "    if need_header:\n",
    "        writer.writeheader()\n",
    "    if buf.getvalue() and not buf.getvalue().endswith(''):\n",
    "        buf.write('')\n",
    "    writer.writerow(row)\n",
    "\n",
    "    private_s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=key,\n",
    "        Body=buf.getvalue().encode('utf-8'),\n",
    "        ContentType='text/csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95340ba3-8b7b-427d-8899-b1a491df5111",
   "metadata": {},
   "source": [
    "**Run recommendation pipeine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddf9d5-6153-4f89-b4bd-ff5ab4782590",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = {\n",
    "    'CL=F',\n",
    "    'ES=F',\n",
    "    'GC=F',\n",
    "    'NQ=F',\n",
    "    'RTY=F',\n",
    "    'YM=F',\n",
    "    'NG=F',\n",
    "    'AUDUSD=X',\n",
    "    'EURJPY=X',\n",
    "    'EURUSD=X',\n",
    "    'GBPJPY=X',\n",
    "    'GBPUSD=X',\n",
    "    'USDCAD=X',\n",
    "    'USDCHF=X',\n",
    "    'USDJPY=X'\n",
    "}\n",
    "\n",
    "successful_run = show_interesting_trades(\n",
    "    run_recommendation_pipeline(\n",
    "        tickers=TICKERS,\n",
    "        period=\"90d\",\n",
    "        interval=\"1d\",\n",
    "        bucket_name=BUCKET,\n",
    "        mapping_file=MAPPING_FILE,\n",
    "        region=REGION  # Add this line\n",
    "    )\n",
    ")\n",
    "\n",
    "run_start = dt.datetime.now()\n",
    "\n",
    "# Generate a run_id (timestamp) for provenance (no Git required)\n",
    "run_id = run_start.strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "# After run: append run log with counters\n",
    "append_runlog_s3(\n",
    "    BUCKET, RUNLOG_KEY,\n",
    "    start_time=run_start,\n",
    "    status=successful_run,\n",
    "    files_processed=0,\n",
    "    files_skipped=0,\n",
    "    files_error=0,\n",
    "    run_id=run_id,\n",
    "    notes='Recommendation run'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fde6be-cdc0-4088-ba1c-7a0be706fe66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
