{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f07e057-7ee1-4187-adbc-01870d6e2a8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Load** the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8135450a-c614-4608-9a4f-a980e289b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numexpr --quiet\n",
    "\n",
    "!pip install pandas --quiet\n",
    "!pip install datetime --quiet\n",
    "!pip install feedparser --quiet\n",
    "!pip install textblob --quiet\n",
    "!pip install yfinance --quiet\n",
    "!pip install requests --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81118871-b728-48e5-831d-f8416ff02d45",
   "metadata": {},
   "source": [
    "**Define a function to get the pricing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58e0da0a-4253-43ca-9c8e-62a1a0c5876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List, Tuple\n",
    "\n",
    "def fetch_price(ticker: str,\n",
    "               period: str, \n",
    "               interval: str) -> pd.DataFrame:\n",
    "    df = yf.download(ticker, period=period, interval=interval, auto_adjust=True, progress=False)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df.reset_index(inplace=True) \n",
    "    df.columns.name = None\n",
    "    df['ticker'] = ticker\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a462df1-7648-4934-8487-fa19c5de5495",
   "metadata": {},
   "source": [
    "**Define a function to compute the technical indicators**\n",
    "1. Compute the MACD\n",
    "2. Compute the RSI\n",
    "3. Compute the ATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7df5833a-1a6f-4854-9c5d-cab34bcee3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with EMA12, EMA26, MACD, Signal, and MACD_hist added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD']  = df['EMA12'] - df['EMA26']\n",
    "    df['Signal']   = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_hist'] = df['MACD'] - df['Signal']\n",
    "    return df\n",
    "\n",
    "def compute_rsi(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period RSI column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    return df\n",
    "\n",
    "def compute_atr(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with a 14-period ATR column added.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    prev_close = df['Close'].shift(1)\n",
    "    tr1 = df['High'] - df['Low']\n",
    "    tr2 = (df['High'] - prev_close).abs()\n",
    "    tr3 = (df['Low']  - prev_close).abs()\n",
    "    df['ATR'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1).rolling(window=window).mean()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b7427-6257-407d-b996-cce27aaab9fc",
   "metadata": {},
   "source": [
    "**Define a function to load the strike prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5018b7b6-74b5-4f15-8f2c-b4d9206518d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_strikes(\n",
    "    path: str,\n",
    "    strike_col: str = \"strike\",\n",
    "    decimals: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1. Reads a CSV from `path`\n",
    "    2. Normalizes column names to lowercase & stripped\n",
    "    3. Ensures there's a numeric `strike_col`, stripping whitespace, converting to float, and rounding\n",
    "    \n",
    "    Returns the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pd.read_csv(path)\n",
    "          # normalize headers: strip whitespace, lowercase\n",
    "          .rename(columns=lambda c: c.strip().lower())\n",
    "          # strip & convert the strike column to numeric, then round\n",
    "          .assign(**{\n",
    "              strike_col: lambda df: (\n",
    "                  pd.to_numeric(\n",
    "                      df[strike_col]\n",
    "                        .astype(str)\n",
    "                        .str.strip(),\n",
    "                      errors=\"raise\"\n",
    "                  )\n",
    "                  .round(decimals)\n",
    "              )\n",
    "          })\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e818b8-8fa1-4cec-8a69-1ec208a838fc",
   "metadata": {},
   "source": [
    "**Define a function to determine the trading signal**\n",
    "1. Determine the Trend\n",
    "2. Check the Momentum\n",
    "3. Determine the Trigger\n",
    "4. Check the Volatility\n",
    "5. Generate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "889eb1cd-4e7d-430d-bbdb-2a4d2c8edd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_trend(row):\n",
    "    \"\"\"\n",
    "    Returns (trend_str, ema_diff) where ema_diff = EMA12 − EMA26.\n",
    "    \"\"\"\n",
    "    diff = row.EMA12 - row.EMA26\n",
    "    if (row.EMA12 > row.EMA26) and (row.Close > row.EMA12) and (row.Close > row.EMA26):\n",
    "        trend = 'up'\n",
    "    elif (row.EMA12 < row.EMA26) and (row.Close < row.EMA12) and (row.Close < row.EMA26):\n",
    "        trend = 'down'\n",
    "    else:\n",
    "        trend = 'sideways'\n",
    "    return trend, diff\n",
    "\n",
    "def momentum_check(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, rsi) where ok is True/False and rsi is the raw RSI value.\n",
    "    \"\"\"\n",
    "    rsi = row.RSI\n",
    "    if trend == 'up':\n",
    "        ok = (rsi > 50) and ((row.MACD > row.Signal) or (row.MACD_hist > 0))\n",
    "    elif trend == 'down':\n",
    "        ok = (rsi < 50) and ((row.MACD < row.Signal) or (row.MACD_hist < 0))\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, rsi\n",
    "\n",
    "def signal_trigger(row, trend):\n",
    "    \"\"\"\n",
    "    Returns (ok, macd_diff) where macd_diff = MACD − Signal.\n",
    "    \"\"\"\n",
    "    macd_diff = row.MACD - row.Signal\n",
    "    if trend == 'up':\n",
    "        ok = (macd_diff > 0) and (row.RSI > 50)\n",
    "    elif trend == 'down':\n",
    "        ok = (macd_diff < 0) and (row.RSI < 50)\n",
    "    else:\n",
    "        ok = False\n",
    "    return ok, macd_diff\n",
    "\n",
    "def volatility_check(row, strike_diff):\n",
    "    \"\"\"\n",
    "    Returns (ok, strike_diff) so you have the raw distance too.\n",
    "    \"\"\"\n",
    "    ok = strike_diff <= 0.5 * row.ATR\n",
    "    return ok, strike_diff\n",
    "\n",
    "def signal_detail_for_row(row, per_ticker, expiry=\"EOD\"):\n",
    "    df = per_ticker[row.ticker]\n",
    "    last = df.iloc[-1]\n",
    "\n",
    "    trend, trend_val = determine_trend(last)\n",
    "    momentum_ok, momentum_val = momentum_check(last, trend)\n",
    "    sig_ok, signal_val = signal_trigger(last, trend)\n",
    "    strike_diff = abs(row.strike - last.Close)\n",
    "    vol_ok, vol_val = volatility_check(last, strike_diff)\n",
    "\n",
    "    # build recommendation + contract price\n",
    "    if (trend == 'sideways'\n",
    "        or not momentum_ok\n",
    "        or not sig_ok\n",
    "        or not vol_ok\n",
    "    ):\n",
    "        rec   = \"No trade\"\n",
    "        price = pd.NA\n",
    "    else:\n",
    "        direction = \"Buy\" if trend == \"up\" else \"Sell\"\n",
    "        price     = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "        rec       = direction\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Date\":           pd.Timestamp.now().strftime(\"%d-%b-%y\"),\n",
    "        \"Ticker\":         row.ticker,\n",
    "        \"Strike\":         row.strike,\n",
    "        \"EMA12\":          last.EMA12,\n",
    "        \"EMA26\":          last.EMA26,\n",
    "        \"MACD\":           last.MACD,\n",
    "        \"RSI\":            last.RSI,\n",
    "        \"ATR\":            last.ATR,\n",
    "        \"Recommendation\": rec,\n",
    "        \"ContractPrice\":  price,\n",
    "        \"Trend\":          trend_val,\n",
    "        \"Momentum\":       momentum_val,\n",
    "        \"Signal\":         signal_val,\n",
    "        \"Volatility\":     vol_val\n",
    "    })\n",
    "\n",
    "def generate_detailed_signals(per_ticker: dict[str,pd.DataFrame],\n",
    "                              strikes_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies signal_detail_for_row to every strike, returning a DataFrame\n",
    "    with separate columns for both the boolean/string and the raw measure.\n",
    "    \"\"\"\n",
    "    return strikes_df.apply(\n",
    "        lambda r: signal_detail_for_row(r, per_ticker),\n",
    "        axis=1\n",
    "    )    \n",
    "\n",
    "def generate_trade_signal(df: pd.DataFrame, asset_symbol: str, strike_price: float, expiry=\"EOD\") -> str:\n",
    "    \"\"\"\n",
    "    Look only at the *last* row of df and decide on a trade recommendation.\n",
    "    \"\"\"\n",
    "    last = df.iloc[-1]\n",
    "    trend = determine_trend(last)\n",
    "    if trend == 'sideways':\n",
    "        return \"No trade: Trend unclear.\"\n",
    "    if trend == 'down':\n",
    "        # optional debug print\n",
    "        print(f\"Down trend for {asset_symbol} at {strike_price:.4f}\")\n",
    "\n",
    "    if not momentum_check(last, trend):\n",
    "        return \"No trade: Momentum not aligned.\"\n",
    "    if not signal_trigger(last, trend):\n",
    "        return \"No trade: No signal trigger.\"\n",
    "\n",
    "    strike_diff = abs(strike_price - last.Close)\n",
    "    if not volatility_check(last, strike_diff):\n",
    "        return \"No trade: Strike too far based on ATR.\"\n",
    "\n",
    "    # crude price proxy\n",
    "    price_est = 10 * (0.5 - (strike_diff / (2 * last.ATR)))\n",
    "    direction = \"Buy\" if trend == 'up' else \"Sell\"\n",
    "    return (\n",
    "        f\"{direction} {asset_symbol} @ {strike_price:.4f} (EOD) ≈ ${price_est:.1f}. \"\n",
    "        f\"{trend.title()} trend, momentum/signal OK, volatility OK.\"\n",
    "    )\n",
    "\n",
    "def generate_all_signals(\n",
    "    per_ticker: dict[str, pd.DataFrame], \n",
    "    strikes_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row in strikes_df, look up its ticker-DF in per_ticker and\n",
    "    call generate_trade_signal.  Returns a DataFrame of recommendations.\n",
    "    \"\"\"\n",
    "    out = (\n",
    "        strikes_df\n",
    "        .assign(\n",
    "            Date=pd.Timestamp.now().strftime('%d-%b-%y'),\n",
    "            Signal=lambda d: d.apply(\n",
    "                lambda r: generate_trade_signal(\n",
    "                    per_ticker[r.ticker],\n",
    "                    r.ticker,\n",
    "                    r.strike\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        .rename(columns={'ticker':'Ticker', 'strike':'Strike'})\n",
    "        [['Date','Ticker','Strike','Signal']]\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1b12-c689-414c-a739-0a7dea03c8b6",
   "metadata": {},
   "source": [
    "**Define a function to run the Pipeline**\n",
    "1. Collect pricing data\n",
    "2. Compute the technical indicators\n",
    "3. Compute the trading signals\n",
    "4. Compare with the day's Strike prices\n",
    "5. Upload the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c098fd63-8ecb-45f6-8908-78d9ef151c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "def run_recommendation_pipeline(tickers: List,\n",
    "                               bucket_name: str,\n",
    "                               period: str,\n",
    "                               interval: str,\n",
    "                               mapping_file: str,\n",
    "                               region: str = None) -> pd.DataFrame:  # Add region param\n",
    "    \"\"\"\n",
    "    Fetch price, compute indicators, load strikes,\n",
    "    and return a DataFrame of trade signals.\n",
    "    \"\"\"\n",
    "    clients = create_s3_clients(region=region)  # Pass region\n",
    "    public_s3 = clients[\"public\"]\n",
    "    private_s3 = clients[\"private\"]\n",
    "    s3_resource = clients[\"resource\"]\n",
    "    buckets = {\n",
    "        \"daily\":  get_bucket(s3_resource, bucket_name),\n",
    "    }\n",
    "\n",
    "    ticker_price_data = [\n",
    "        (ticker, fetch_price(ticker, period, interval))\n",
    "        for ticker in tickers\n",
    "    ]\n",
    "\n",
    "    processed = {\n",
    "        ticker: (\n",
    "            df\n",
    "              .pipe(compute_macd)\n",
    "              .pipe(compute_rsi)\n",
    "              .pipe(compute_atr)\n",
    "        )\n",
    "        for ticker, df in ticker_price_data\n",
    "    }\n",
    "    strikes_df = load_strikes(mapping_file)\n",
    "    signals_df = generate_detailed_signals(processed, strikes_df)\n",
    "\n",
    "    today_str = date.today().strftime('%Y%m%d')\n",
    "\n",
    "    s3_key = f\"{RECS_PREFIX}/{today_str}.csv\"\n",
    "    upload_df_to_s3(\n",
    "        signals_df,\n",
    "        bucket_name,\n",
    "        s3_key,\n",
    "        region=region  # Add this line\n",
    "    )\n",
    "    return signals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d39070-1575-404b-b913-5db05955047b",
   "metadata": {},
   "source": [
    "**Define a function to show interesting trades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "691e8131-e1e0-4856-a7d1-4c271cd7ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def show_interesting_trades(df: pd.DataFrame) -> str:\n",
    "    interesting_trades_df = df[\n",
    "        ~df['Recommendation']\n",
    "            .str.contains(\"No trade\", case=False, na=False)\n",
    "    ]\n",
    "    if not interesting_trades_df.empty:\n",
    "        print(\n",
    "            tabulate(\n",
    "                interesting_trades_df[[\"Date\",\"Ticker\",\"Recommendation\",\"Strike\",\"ContractPrice\"]],\n",
    "                headers='keys',\n",
    "                tablefmt='fancy_grid',\n",
    "                showindex=False,        \n",
    "                maxcolwidths=200  \n",
    "            )\n",
    "        )\n",
    "        return 'Success'\n",
    "    else:\n",
    "        print(\"No trades recommended today\")\n",
    "        return 'Failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a12b8-4075-4f3e-907c-57d197aa934c",
   "metadata": {},
   "source": [
    "**Load from configuration files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d3cf079-7be9-4f19-b791-d4392d313555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region = us-west-2\n"
     ]
    }
   ],
   "source": [
    "# Load config (run from inside notebooks/)\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../lib\")  # so we can \"from lib import ...\" package-style\n",
    "\n",
    "from strategy_rsi import generate_rsi_signals      # shared RSI/MACD/centerline/reversal logic\n",
    "# (Optional) other helpers you'll likely use:\n",
    "from utils_s3 import save_dataframe_to_s3, save_text_to_s3, append_runlog_s3\n",
    "\n",
    "# s3 + strategy configs\n",
    "with open('../configs/s3.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# S3 targets / prefixes\n",
    "BUCKET = cfg['bucket']\n",
    "REGION = cfg.get('region')\n",
    "RECS_PREFIX = cfg['prefixes'].get('recommendations', 'recommendations')\n",
    "REPORTS_PREFIX = cfg['prefixes'].get('reports', 'reports')\n",
    "RUNLOG_KEY = f\"{cfg['prefixes'].get('logs','logs')}/run_log.csv\"\n",
    "\n",
    "print(f\"Region = {REGION}\")\n",
    "\n",
    "# Optional mapping file (primarily used by Nadex-results; harmless if unused here)\n",
    "MAPPING_FILE = Path(cfg.get('mapping_file')).resolve() if cfg.get('mapping_file') else None\n",
    "\n",
    "# Optional: guard to prevent accidental hard-coding at runtime\n",
    "ALLOWED_BUCKETS = {BUCKET}\n",
    "\n",
    "def assert_allowed_bucket(b):\n",
    "    if b not in ALLOWED_BUCKETS:\n",
    "        raise ValueError(\n",
    "            f\"Bucket '{b}' not allowed; use cfg['bucket'] from s3.yaml.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95340ba3-8b7b-427d-8899-b1a491df5111",
   "metadata": {},
   "source": [
    "**Run recommendation pipeine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddf9d5-6153-4f89-b4bd-ff5ab4782590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded to s3://nadex-daily-results/recommendations/20251120.csv\n",
      "╒═══════════╤══════════╤══════════════════╤══════════╤═════════════════╕\n",
      "│ Date      │ Ticker   │ Recommendation   │   Strike │   ContractPrice │\n",
      "╞═══════════╪══════════╪══════════════════╪══════════╪═════════════════╡\n",
      "│ 20-Nov-25 │ AUDUSD=X │ Sell             │    0.646 │         3.55839 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 20-Nov-25 │ AUDUSD=X │ Sell             │    0.644 │         4.52454 │\n",
      "├───────────┼──────────┼──────────────────┼──────────┼─────────────────┤\n",
      "│ 20-Nov-25 │ AUDUSD=X │ Sell             │    0.642 │         2.60747 │\n",
      "╘═══════════╧══════════╧══════════════════╧══════════╧═════════════════╛\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "append_runlog_s3() missing 1 required positional argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m run_id = run_start.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33mT\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# After run: append run log with counters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mappend_runlog_s3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBUCKET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRUNLOG_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuccessful_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles_processed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles_skipped\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles_error\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnotes\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRecommendation run\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     45\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: append_runlog_s3() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "TICKERS = {\n",
    "    'CL=F',\n",
    "    'ES=F',\n",
    "    'GC=F',\n",
    "    'NQ=F',\n",
    "    'RTY=F',\n",
    "    'YM=F',\n",
    "    'NG=F',\n",
    "    'AUDUSD=X',\n",
    "    'EURJPY=X',\n",
    "    'EURUSD=X',\n",
    "    'GBPJPY=X',\n",
    "    'GBPUSD=X',\n",
    "    'USDCAD=X',\n",
    "    'USDCHF=X',\n",
    "    'USDJPY=X'\n",
    "}\n",
    "\n",
    "# Track run start time\n",
    "run_start = dt.datetime.now()\n",
    "run_id = run_start.strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "# Run the pipeline\n",
    "successful_run = show_interesting_trades(\n",
    "    run_recommendation_pipeline(\n",
    "        tickers=TICKERS,\n",
    "        period=\"90d\",\n",
    "        interval=\"1d\",\n",
    "        bucket_name=BUCKET,\n",
    "        mapping_file=MAPPING_FILE,\n",
    "        region=REGION\n",
    "    )\n",
    ")\n",
    "\n",
    "# ✅ CREATE S3 CLIENT FIRST (this is what was missing!)\n",
    "clients = create_s3_clients(region=REGION)\n",
    "private_s3 = clients[\"private\"]\n",
    "\n",
    "# ✅ NOW CALL append_runlog_s3 WITH ALL REQUIRED PARAMETERS\n",
    "append_runlog_s3(\n",
    "    private_s3,      # ← FIRST: s3_client \n",
    "    BUCKET,          # ← SECOND: bucket\n",
    "    RUNLOG_KEY,      # ← THIRD: key\n",
    "    start_time=run_start,\n",
    "    status=successful_run,\n",
    "    files_processed=0,\n",
    "    files_skipped=0,\n",
    "    files_error=0,\n",
    "    run_id=run_id,\n",
    "    notes='Recommendation run'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Run complete: {run_id}\")\n",
    "print(f\"   Status: {successful_run}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fde6be-cdc0-4088-ba1c-7a0be706fe66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
